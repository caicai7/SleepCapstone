class DeepSleepNet_Classification(nn.Module):  
    def __init__(self,in_channel=1,out_channel=6,layer=[64,128,256,256],sample_rate = 100):
        super(DeepSleepNet_Classification, self).__init__()


        self.conv1d_1 = nn.Conv1d(1,16, kernel_size=300, stride=50)
        self.conv1d_2 = nn.Conv1d(16, 32, kernel_size=10, stride=5)
        self.pool = nn.MaxPool2d(2,2)
        self.fc1 = nn.Linear(320,160)
        self.fc2 = nn.Linear(160,out_channel)
         

        self.PReLU = nn.PReLU()
        
        self.dropout = nn.Dropout(p=0.2)

    def forward(self, input):
        out = self.conv1d_1(input)
        out = self.PReLU(out)
       
        out = self.dropout(out)
        out = self.conv1d_2(out)
        out = self.PReLU(out)
       
        out = self.dropout(out)
        out = torch.flatten(out, 1)
        out = self.fc1(out)
        out = self.PReLU(out)
        
        out = self.fc2(out)
        out = self.PReLU(out)
       
       
       current_lr : 0.000008
train dataset : 123/2000 epochs spend time : 0.7354 sec / total_loss : 0.8372 correct : 20244/29356 -> 68.9603%
test dataset : 123/2000 epochs spend time : 0.1851 sec  / total_loss : 0.9832 correct : 5855/9064 -> 64.5962%
Early Stopping
best epoch : 92/2000 / accuracy : 65.346425%

PReLU 함수도 한번 써봤습니다! 근데 확실히 Reaky보다는 낮게 나오는 것 같습니다!

PReLU는

f(x)=max(αx,x)

Leakly ReLU와 거의 유사하지만 새로운 파라미터 α 를 추가하여 x<0에서 기울기를 학습할 수 있게 한다.
